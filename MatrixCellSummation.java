import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.chain.ChainMapper;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.MultipleInputs;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;
import java.text.DecimalFormat;

/**
 * This class is driver application to start map and reduce jobs.
 */
public class MatrixCellSummation {
	// This class reads all lines from multiplication result, splits data in each line, and put splitted data into context.
    public static class PassMapper extends Mapper<Object, Text, Text, DoubleWritable> {
		// Process one line of data.
        @Override
        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            String[] pageSubrank = value.toString().trim().split("\t"); // Convert one line of data from multiplication result to String format, and split data into String array.
            double subRank = Double.parseDouble(pageSubrank[1]); // Convert calculated PageRank score into double format.
            context.write(new Text(pageSubrank[0]), new DoubleWritable(subRank)); // Put linked page ID and calculated PageRank score into context.
        }
    }

    // This class reads all lines in prX.txt, splits data in each line, and put splitted and calculated data into context.
    public static class BetaMapper extends Mapper<Object, Text, Text, DoubleWritable> {
        private float beta;

        // Get damping factor from context, and assign to beta variable.
        @Override
        public void setup(Context context) {
            Configuration conf = context.getConfiguration();
            beta = conf.getFloat("beta", 0.2f);
        }

        // Process one line of data.
        @Override
        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            String[] pageRank = value.toString().trim().split("\t"); // Convert one line of data in prX.txt to String format, and split data into String array.
            double betaRank = Double.parseDouble(pageRank[1]) * beta; // Each start page's PageRank score times damping factor.
            context.write(new Text(pageRank[0]), new DoubleWritable(betaRank)); //  Put start page ID and revised start page's PageRank score into context.
        }
    }

    // This class calculate PageRank scores of each page ID.
    public static class SummationReducer extends Reducer<Text, DoubleWritable, Text, DoubleWritable> {
		// Process all values associated with a key.
        @Override
        public void reduce(Text key, Iterable<DoubleWritable> values, Context context) throws IOException, InterruptedException {
            double sum = 0;
			
			// For each page(no matter start page ID or linked page) ID as key, for this iteration, the PageRank score is the sum of values as input argument.
            for (DoubleWritable value : values) {
                sum += value.get(); 
            }

            DecimalFormat formatter = new DecimalFormat("#.0000");
            sum = Double.valueOf(formatter.format(sum)); // Format the sum.
            context.write(key, new DoubleWritable(sum)); // Put page ID and its PageRank score into context.
        }
    }

    public static void main(String[] args) throws Exception {
        Path subPageRankPath = new Path(args[0]); // Create path to retrieve multiplication result file generated by MatrixCellMultiplication file.
        Path prevPageRankPath = new Path(args[1]); // Create path to retrieve file for each page's PageRank score as of last iteration.
        Path outputPath = new Path(args[2]); // Create path to place output file.
        float beta = 0.2f; // Create a default damping factor if user misses this.

        if (args.length > 3) {
            beta = Float.parseFloat(args[3]); // Assign to beta if user has defined damping factor.
        }

        Configuration conf = new Configuration();
        conf.setFloat("beta", beta); // Put damping factor into configuration, so that mapper and reducer class can use.

        Job job = Job.getInstance(conf);
        job.setJarByClass(MatrixCellSummation.class); // Set up JAR file.

        // Set up input and output format for two map classes, and pass external configuration to two classes.
        ChainMapper.addMapper(job, PassMapper.class, Object.class, Text.class, Text.class, DoubleWritable.class, conf);
        ChainMapper.addMapper(job, BetaMapper.class, Text.class, DoubleWritable.class, Text.class, DoubleWritable.class, conf);

        job.setReducerClass(SummationReducer.class); // Set up reduce class.
        job.setOutputKeyClass(Text.class); // Set up output key data type.
        job.setOutputValueClass(DoubleWritable.class); // Set up output value data type.

        // Assign input file paths for mapper classes, and output file paths for reducer class.
        MultipleInputs.addInputPath(job, subPageRankPath, TextInputFormat.class, PassMapper.class);
        MultipleInputs.addInputPath(job, prevPageRankPath, TextInputFormat.class, BetaMapper.class);
        FileOutputFormat.setOutputPath(job, outputPath);
		
        job.waitForCompletion(true);
    }
}